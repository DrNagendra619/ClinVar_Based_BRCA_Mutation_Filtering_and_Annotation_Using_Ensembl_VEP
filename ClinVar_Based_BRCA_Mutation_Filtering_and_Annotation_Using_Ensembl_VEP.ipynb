{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C9xFRzDtAzZv"
      },
      "outputs": [],
      "source": [
        "# Step 1: Download ClinVar Mutation Dataset\n",
        "import requests, gzip, pandas as pd, os, json\n",
        "\n",
        "clinvar_url = \"https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz\"\n",
        "clinvar_file = \"variant_summary.txt.gz\"\n",
        "\n",
        "if not os.path.exists(clinvar_file):\n",
        "    response = requests.get(clinvar_url)\n",
        "    with open(clinvar_file, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(\"File already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and Inspect the Dataset in Chunks\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "clinvar_file = \"variant_summary.txt.gz\"\n",
        "chunk_size = 100000  # Define a suitable chunk size\n",
        "\n",
        "# Initialize an empty list to store processed chunks\n",
        "chunk_list = []\n",
        "\n",
        "with gzip.open(clinvar_file, 'rt') as f:\n",
        "    # Read the header separately to use with chunks\n",
        "    header = f.readline().strip().split('\\t')\n",
        "    # Read the rest of the file in chunks\n",
        "    for chunk in pd.read_csv(f, sep='\\t', dtype={'18': str}, low_memory=False, chunksize=chunk_size, header=None):\n",
        "        # Assign column names from the header\n",
        "        chunk.columns = header\n",
        "        chunk_list.append(chunk)\n",
        "\n",
        "# Concatenate the processed chunks if needed later, but we will process chunks in Step 3\n",
        "# data = pd.concat(chunk_list, ignore_index=True)\n",
        "\n",
        "print(\"Data loaded in chunks.\")\n",
        "# We won't print columns here as 'data' as a whole is not loaded"
      ],
      "metadata": {
        "id": "oUVfjXKxBoFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1feabc-905d-4fa5-80b3-6a0e3e062ffb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded in chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 3: Filter for BRCA1/BRCA2 Breast Cancer Mutations (Processing Chunks)\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure chunk_list is available from Step 2\n",
        "if 'chunk_list' not in locals():\n",
        "    print(\"Error: chunk_list not found. Please run Step 2 first.\")\n",
        "else:\n",
        "    bc_data_list = []\n",
        "    for data_chunk in chunk_list:\n",
        "        # Apply the filtering criteria to each chunk\n",
        "        bc_chunk = data_chunk[\n",
        "            (data_chunk['GeneSymbol'].isin(['BRCA1', 'BRCA2'])) &\n",
        "            (data_chunk['PhenotypeList'].str.contains(\"Breast\", na=False))\n",
        "        ]\n",
        "\n",
        "        # Apply the MinorAlleleFreq filter if the column exists\n",
        "        if 'MinorAlleleFreq' in bc_chunk.columns:\n",
        "             bc_chunk = bc_chunk[bc_chunk['MinorAlleleFreq'].fillna(0).astype(float) <= 0.01]\n",
        "\n",
        "\n",
        "        bc_data_list.append(bc_chunk)\n",
        "\n",
        "    # Concatenate the filtered chunks into a single DataFrame\n",
        "    bc_data = pd.concat(bc_data_list, ignore_index=True)\n",
        "\n",
        "    bc_data.to_csv(\"filtered_mutations.csv\", index=False)\n",
        "    print(\"Filtered mutations saved to filtered_mutations.csv\")"
      ],
      "metadata": {
        "id": "mJfl791WBrKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae8a3b6-7d8c-4514-d856-60843fc620a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered mutations saved to filtered_mutations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 4: Prepare Mutation Payload for Ensembl VEP and Iterate\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Use the first few variants from the filtered data for testing\n",
        "variants_to_try = 5\n",
        "annotated_variant = None\n",
        "\n",
        "for i in range(min(variants_to_try, len(bc_data))):\n",
        "    example_variant = bc_data.iloc[i]\n",
        "\n",
        "    # Construct the variant ID in VCF-like format (chromosome:position:reference:alternate)\n",
        "    # Using PositionVCF, ReferenceAlleleVCF, and AlternateAlleleVCF columns\n",
        "    variant_id = str(example_variant['Chromosome']) + \":\" + str(example_variant['PositionVCF']) + \":\" + str(example_variant['ReferenceAlleleVCF']) + \":\" + str(example_variant['AlternateAlleleVCF'])\n",
        "\n",
        "    # Mutation dictionary format for VEP ID endpoint\n",
        "    mutation = {\n",
        "        \"ids\": [variant_id], # Use 'ids' for the /id endpoint\n",
        "        \"assembly\": \"GRCh37\" # Specify the assembly to match the input data\n",
        "    }\n",
        "\n",
        "    # Change the VEP API endpoint to /vep/human/id\n",
        "    vep_url = \"https://rest.ensembl.org/vep/human/id\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    print(f\"Attempting to annotate variant {i+1}: {variant_id}\")\n",
        "\n",
        "    # Send to Ensembl VEP API\n",
        "    response = requests.post(vep_url, headers=headers, data=json.dumps(mutation))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        annotation = response.json()\n",
        "        if annotation: # Check if the annotation list is not empty\n",
        "            print(f\"Successfully annotated variant {i+1}.\")\n",
        "            annotated_variant = annotation[0] # Store the first successful annotation\n",
        "            break # Stop iterating on success\n",
        "        else:\n",
        "            print(f\"Variant {i+1} found, but no annotation returned.\")\n",
        "    elif response.status_code == 400:\n",
        "        print(f\"VEP failed for variant {i+1}: {response.status_code} - Bad Request.\")\n",
        "        try:\n",
        "            error_details = response.json()\n",
        "            print(f\"Error details: {error_details}\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Response text: {response.text}\")\n",
        "    else:\n",
        "        print(f\"VEP failed for variant {i+1}: {response.status_code}\")\n",
        "        print(f\"Response text: {response.text}\")\n",
        "\n",
        "    time.sleep(1) # Add a small delay between requests\n",
        "\n",
        "if annotated_variant:\n",
        "    print(\"\\nFound a successfully annotated variant.\")\n",
        "    # You can now use annotated_variant for further steps\n",
        "    # For example, print the keys in the annotation:\n",
        "    # print(annotated_variant.keys())\n",
        "else:\n",
        "    print(\"\\nCould not successfully annotate any of the first few variants.\")"
      ],
      "metadata": {
        "id": "i-RMba26BuYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02c4b46-abd4-4584-fc75-b43c96760c71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to annotate variant 1: 13:32921028:CTTTCGG:C\n",
            "VEP failed for variant 1: 400 - Bad Request.\n",
            "Error details: {'error': \"No variant found with ID '13:32921028:CTTTCGG:C'\"}\n",
            "Attempting to annotate variant 2: 13:32346891:CTTTCGG:C\n",
            "VEP failed for variant 2: 400 - Bad Request.\n",
            "Error details: {'error': \"No variant found with ID '13:32346891:CTTTCGG:C'\"}\n",
            "Attempting to annotate variant 3: 13:32914766:CTT:C\n",
            "VEP failed for variant 3: 400 - Bad Request.\n",
            "Error details: {'error': \"No variant found with ID '13:32914766:CTT:C'\"}\n",
            "Attempting to annotate variant 4: 13:32340629:CTT:C\n",
            "VEP failed for variant 4: 400 - Bad Request.\n",
            "Error details: {'error': \"No variant found with ID '13:32340629:CTT:C'\"}\n",
            "Attempting to annotate variant 5: 13:32915082:CTG:C\n",
            "VEP failed for variant 5: 400 - Bad Request.\n",
            "Error details: {'error': \"No variant found with ID '13:32915082:CTG:C'\"}\n",
            "\n",
            "Could not successfully annotate any of the first few variants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Save the Successfully Annotated Variant (if found)\n",
        "import json\n",
        "\n",
        "# Ensure annotated_variant is available from Step 4\n",
        "if 'annotated_variant' in locals() and annotated_variant is not None:\n",
        "    with open(\"vep_annotation.json\", \"w\") as f:\n",
        "        json.dump(annotated_variant, f, indent=4)\n",
        "    print(\"Successfully annotated variant saved to vep_annotation.json\")\n",
        "else:\n",
        "    print(\"No successfully annotated variant found in Step 4. Skipping Step 5.\")"
      ],
      "metadata": {
        "id": "cnVMiZ1MBxlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f89993-1794-4e5e-871a-b3b1efa010ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No successfully annotated variant found in Step 4. Skipping Step 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Simulate Pathogenicity Scores\n",
        "bc_data[\"PolyPhen\"] = [0.9] * len(bc_data)\n",
        "bc_data[\"SIFT\"] = [0.01] * len(bc_data)\n",
        "\n",
        "# High = damaging\n",
        "# Low = damaging\n"
      ],
      "metadata": {
        "id": "-176vppVB0vz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Filter Pathogenic Mutations\n",
        "pathogenic = bc_data[\n",
        "    (bc_data[\"PolyPhen\"] > 0.85) &\n",
        "    (bc_data[\"SIFT\"] < 0.05)\n",
        "]\n",
        "\n",
        "pathogenic.to_csv(\"pathogenic_mutations.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "oV3bZo1VB33I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Download Results (Google Colab Only)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"filtered_mutations.csv\")\n",
        "    files.download(\"pathogenic_mutations.csv\")\n",
        "    files.download(\"vep_annotation.json\")\n",
        "except:\n",
        "    print(\"Download only works in Google Colab.\")\n"
      ],
      "metadata": {
        "id": "38xe8CiAB69U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "378ff621-96c8-4d87-a83b-4ccb03f955f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bdd3a992-73f7-4f53-88bb-17ecc70858ec\", \"filtered_mutations.csv\", 23881321)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb56fe7f-8d36-4ad0-90d7-5d6860d60505\", \"pathogenic_mutations.csv\", 24184140)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download only works in Google Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: List Files in Current Directory\n",
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "id": "mRFhukBKB9nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95937f39-cd20-40f8-cb84-35182bd119b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'pathogenic_mutations.csv', 'variant_summary.txt.gz', 'filtered_mutations.csv', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f98f6e7e"
      },
      "source": [
        "**Detailed Final Interpretation of Findings:**\n",
        "\n",
        "*   The initial ClinVar mutation dataset was successfully downloaded and processed efficiently by reading it in chunks to manage memory usage.\n",
        "*   The data was then filtered to specifically identify mutations in the BRCA1 and BRCA2 genes that are associated with a \"Breast\" phenotype and have a minor allele frequency (MAF) of 0.01 or less.\n",
        "*   This filtering process resulted in a dataset of potentially relevant mutations, which was saved to `filtered_mutations.csv`.\n",
        "*   An attempt was made to obtain detailed functional annotations and predicted pathogenicity scores (like PolyPhen and SIFT) for these filtered variants using the Ensembl VEP API.\n",
        "*   However, the VEP annotation step was unsuccessful because the specific variants from the ClinVar dataset could not be found in the Ensembl VEP database using the provided identifiers and the GRCh37 assembly.\n",
        "*   Due to the failure to obtain real pathogenicity scores from VEP, placeholder scores for PolyPhen and SIFT were simulated for all filtered variants.\n",
        "*   Using these *simulated* pathogenicity scores, the filtered mutations were further analyzed to identify those classified as \"pathogenic\" based on predefined thresholds (PolyPhen > 0.85 and SIFT < 0.05).\n",
        "*   The list of mutations classified as pathogenic based on these simulated scores was saved to `pathogenic_mutations.csv`.\n",
        "*   The generated files (`filtered_mutations.csv` and `pathogenic_mutations.csv`) containing the filtered and simulated pathogenic mutation lists are available for download.\n",
        "*   Note that the pathogenicity classification in `pathogenic_mutations.csv` is based on *simulated* scores due to the VEP annotation failure and may not reflect actual predicted or clinically determined pathogenicity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8977b3f8"
      },
      "source": [
        "**Conclusion of the Workflow:**\n",
        "\n",
        "*   We successfully downloaded a large ClinVar mutation dataset.\n",
        "*   The dataset was loaded and processed efficiently in chunks to manage memory.\n",
        "*   We filtered the data to identify BRCA1/BRCA2 mutations related to breast cancer with low minor allele frequency.\n",
        "*   An attempt was made to get functional annotations from the Ensembl VEP API, but the specific variants could not be found in the database.\n",
        "*   Due to the VEP annotation failure, pathogenicity scores were simulated for the filtered variants.\n",
        "*   We then filtered the mutations based on these simulated scores to identify potentially pathogenic variants.\n",
        "*   Finally, the filtered and \"pathogenic\" mutation lists (based on simulated data) were saved to CSV files."
      ]
    }
  ]
}